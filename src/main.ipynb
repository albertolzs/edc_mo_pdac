{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4615a83d-b9cd-4c1d-84df-d5e75c894c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/alberto/Work/course_interpretability_deep_learning\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a073f0-ba9d-4545-a0f4-a49d638b7695",
   "metadata": {},
   "source": [
    "# Multi-omics stratification on PDAC patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa7dffc4-d560-47bb-84b8-a6870d4824a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from torch.utils.data import DataLoader\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from src import settings\n",
    "from utils import RemovePatientsWithZeros, RemovePatientsWithNaN, FeatureSelectionNMF, RemoveCorrelatedFeatures, RemoveFeaturesLowMAE, \\\n",
    "    MultiViewDataset\n",
    "from model import MVAutoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5991e212-7498-4da5-b089-c355594b1113",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "525e21f1-eb98-424d-91e1-328329b4e786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "methylation_data.shape (153, 301195)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cg00000029</th>\n",
       "      <th>cg00000236</th>\n",
       "      <th>cg00000289</th>\n",
       "      <th>cg00000292</th>\n",
       "      <th>cg00000321</th>\n",
       "      <th>cg00000622</th>\n",
       "      <th>cg00000658</th>\n",
       "      <th>cg00000714</th>\n",
       "      <th>cg00000721</th>\n",
       "      <th>cg00000734</th>\n",
       "      <th>...</th>\n",
       "      <th>ch.9.2262725R</th>\n",
       "      <th>ch.9.2285199R</th>\n",
       "      <th>ch.9.2298007R</th>\n",
       "      <th>ch.9.2473665R</th>\n",
       "      <th>ch.9.357218F</th>\n",
       "      <th>ch.9.377428R</th>\n",
       "      <th>ch.9.691424R</th>\n",
       "      <th>ch.9.837340R</th>\n",
       "      <th>ch.9.898515R</th>\n",
       "      <th>ch.9.991104F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA-2J-AAB6</th>\n",
       "      <td>0.157951</td>\n",
       "      <td>0.836226</td>\n",
       "      <td>0.710511</td>\n",
       "      <td>0.560780</td>\n",
       "      <td>0.239194</td>\n",
       "      <td>0.016433</td>\n",
       "      <td>0.864604</td>\n",
       "      <td>0.087681</td>\n",
       "      <td>0.938775</td>\n",
       "      <td>0.061008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103136</td>\n",
       "      <td>0.053757</td>\n",
       "      <td>0.032478</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.064965</td>\n",
       "      <td>0.049776</td>\n",
       "      <td>0.115268</td>\n",
       "      <td>0.095954</td>\n",
       "      <td>0.084203</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-2J-AAB8</th>\n",
       "      <td>0.300754</td>\n",
       "      <td>0.782242</td>\n",
       "      <td>0.574296</td>\n",
       "      <td>0.670286</td>\n",
       "      <td>0.424310</td>\n",
       "      <td>0.014747</td>\n",
       "      <td>0.885958</td>\n",
       "      <td>0.112524</td>\n",
       "      <td>0.930765</td>\n",
       "      <td>0.037198</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028180</td>\n",
       "      <td>0.054483</td>\n",
       "      <td>0.022736</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.060835</td>\n",
       "      <td>0.036434</td>\n",
       "      <td>0.160082</td>\n",
       "      <td>0.059216</td>\n",
       "      <td>0.065342</td>\n",
       "      <td>0.166304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-2J-AAB9</th>\n",
       "      <td>0.257807</td>\n",
       "      <td>0.846522</td>\n",
       "      <td>0.534748</td>\n",
       "      <td>0.688073</td>\n",
       "      <td>0.295597</td>\n",
       "      <td>0.014649</td>\n",
       "      <td>0.895039</td>\n",
       "      <td>0.167297</td>\n",
       "      <td>0.940112</td>\n",
       "      <td>0.058407</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059313</td>\n",
       "      <td>0.063187</td>\n",
       "      <td>0.032581</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.055342</td>\n",
       "      <td>0.069086</td>\n",
       "      <td>0.128546</td>\n",
       "      <td>0.120015</td>\n",
       "      <td>0.074940</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-2J-AABA</th>\n",
       "      <td>0.239086</td>\n",
       "      <td>0.789457</td>\n",
       "      <td>0.474723</td>\n",
       "      <td>0.705372</td>\n",
       "      <td>0.530321</td>\n",
       "      <td>0.016919</td>\n",
       "      <td>0.884874</td>\n",
       "      <td>0.129581</td>\n",
       "      <td>0.910885</td>\n",
       "      <td>0.062167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.122677</td>\n",
       "      <td>0.056068</td>\n",
       "      <td>0.023190</td>\n",
       "      <td>0.109351</td>\n",
       "      <td>0.056015</td>\n",
       "      <td>0.053238</td>\n",
       "      <td>0.082979</td>\n",
       "      <td>0.057172</td>\n",
       "      <td>0.045781</td>\n",
       "      <td>0.121676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-2J-AABE</th>\n",
       "      <td>0.168622</td>\n",
       "      <td>0.841684</td>\n",
       "      <td>0.591205</td>\n",
       "      <td>0.623799</td>\n",
       "      <td>0.322576</td>\n",
       "      <td>0.014408</td>\n",
       "      <td>0.898202</td>\n",
       "      <td>0.125415</td>\n",
       "      <td>0.941153</td>\n",
       "      <td>0.059365</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046699</td>\n",
       "      <td>0.049177</td>\n",
       "      <td>0.032707</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.075854</td>\n",
       "      <td>0.062602</td>\n",
       "      <td>0.122072</td>\n",
       "      <td>0.082753</td>\n",
       "      <td>0.071240</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 301195 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              cg00000029  cg00000236  cg00000289  cg00000292  cg00000321   \n",
       "TCGA-2J-AAB6    0.157951    0.836226    0.710511    0.560780    0.239194  \\\n",
       "TCGA-2J-AAB8    0.300754    0.782242    0.574296    0.670286    0.424310   \n",
       "TCGA-2J-AAB9    0.257807    0.846522    0.534748    0.688073    0.295597   \n",
       "TCGA-2J-AABA    0.239086    0.789457    0.474723    0.705372    0.530321   \n",
       "TCGA-2J-AABE    0.168622    0.841684    0.591205    0.623799    0.322576   \n",
       "\n",
       "              cg00000622  cg00000658  cg00000714  cg00000721  cg00000734  ...   \n",
       "TCGA-2J-AAB6    0.016433    0.864604    0.087681    0.938775    0.061008  ...  \\\n",
       "TCGA-2J-AAB8    0.014747    0.885958    0.112524    0.930765    0.037198  ...   \n",
       "TCGA-2J-AAB9    0.014649    0.895039    0.167297    0.940112    0.058407  ...   \n",
       "TCGA-2J-AABA    0.016919    0.884874    0.129581    0.910885    0.062167  ...   \n",
       "TCGA-2J-AABE    0.014408    0.898202    0.125415    0.941153    0.059365  ...   \n",
       "\n",
       "              ch.9.2262725R  ch.9.2285199R  ch.9.2298007R  ch.9.2473665R   \n",
       "TCGA-2J-AAB6       0.103136       0.053757       0.032478            NaN  \\\n",
       "TCGA-2J-AAB8       0.028180       0.054483       0.022736            NaN   \n",
       "TCGA-2J-AAB9       0.059313       0.063187       0.032581            NaN   \n",
       "TCGA-2J-AABA       0.122677       0.056068       0.023190       0.109351   \n",
       "TCGA-2J-AABE       0.046699       0.049177       0.032707            NaN   \n",
       "\n",
       "              ch.9.357218F  ch.9.377428R  ch.9.691424R  ch.9.837340R   \n",
       "TCGA-2J-AAB6      0.064965      0.049776      0.115268      0.095954  \\\n",
       "TCGA-2J-AAB8      0.060835      0.036434      0.160082      0.059216   \n",
       "TCGA-2J-AAB9      0.055342      0.069086      0.128546      0.120015   \n",
       "TCGA-2J-AABA      0.056015      0.053238      0.082979      0.057172   \n",
       "TCGA-2J-AABE      0.075854      0.062602      0.122072      0.082753   \n",
       "\n",
       "              ch.9.898515R  ch.9.991104F  \n",
       "TCGA-2J-AAB6      0.084203           NaN  \n",
       "TCGA-2J-AAB8      0.065342      0.166304  \n",
       "TCGA-2J-AAB9      0.074940           NaN  \n",
       "TCGA-2J-AABA      0.045781      0.121676  \n",
       "TCGA-2J-AABE      0.071240           NaN  \n",
       "\n",
       "[5 rows x 301195 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "methylation_data = pd.read_csv(settings.methylation_data_path, sep=\";\", index_col=0, decimal=\",\")\n",
    "methylation_data.columns = methylation_data.columns.str.replace(\".\", \"-\")\n",
    "methylation_data = methylation_data.T\n",
    "methylation_data = methylation_data.astype(np.float32)\n",
    "print(\"methylation_data.shape\", methylation_data.shape)\n",
    "methylation_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ba9fa3a-ba17-49a1-86ef-6b399dfaafed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnaseq_data.shape (147, 20501)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1BG</th>\n",
       "      <th>A1CF</th>\n",
       "      <th>A2BP1</th>\n",
       "      <th>A2LD1</th>\n",
       "      <th>A2ML1</th>\n",
       "      <th>A2M</th>\n",
       "      <th>A4GALT</th>\n",
       "      <th>A4GNT</th>\n",
       "      <th>AAA1</th>\n",
       "      <th>AAAS</th>\n",
       "      <th>...</th>\n",
       "      <th>ZXDA</th>\n",
       "      <th>ZXDB</th>\n",
       "      <th>ZXDC</th>\n",
       "      <th>ZYG11A</th>\n",
       "      <th>ZYG11B</th>\n",
       "      <th>ZYX</th>\n",
       "      <th>ZZEF1</th>\n",
       "      <th>ZZZ3</th>\n",
       "      <th>psiTPTE22</th>\n",
       "      <th>tAKR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA-2J-AAB6</th>\n",
       "      <td>82.549698</td>\n",
       "      <td>8.187100</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>163.122803</td>\n",
       "      <td>1815.789551</td>\n",
       "      <td>8517.444336</td>\n",
       "      <td>1121.052612</td>\n",
       "      <td>1.169600</td>\n",
       "      <td>1.1696</td>\n",
       "      <td>834.502930</td>\n",
       "      <td>...</td>\n",
       "      <td>14.619900</td>\n",
       "      <td>269.005798</td>\n",
       "      <td>1053.216431</td>\n",
       "      <td>0.5848</td>\n",
       "      <td>683.625671</td>\n",
       "      <td>11696.491211</td>\n",
       "      <td>869.005798</td>\n",
       "      <td>601.754395</td>\n",
       "      <td>26.315800</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-2J-AAB8</th>\n",
       "      <td>56.930698</td>\n",
       "      <td>33.842499</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>185.814301</td>\n",
       "      <td>16.921301</td>\n",
       "      <td>14413.913086</td>\n",
       "      <td>392.949493</td>\n",
       "      <td>9.400700</td>\n",
       "      <td>0.9401</td>\n",
       "      <td>801.880127</td>\n",
       "      <td>...</td>\n",
       "      <td>35.722698</td>\n",
       "      <td>356.286713</td>\n",
       "      <td>829.142212</td>\n",
       "      <td>3.7603</td>\n",
       "      <td>680.611023</td>\n",
       "      <td>5829.377441</td>\n",
       "      <td>828.202087</td>\n",
       "      <td>609.165710</td>\n",
       "      <td>85.546402</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-2J-AAB9</th>\n",
       "      <td>105.787804</td>\n",
       "      <td>21.436199</td>\n",
       "      <td>1.0718</td>\n",
       "      <td>166.709503</td>\n",
       "      <td>642.015015</td>\n",
       "      <td>24311.779297</td>\n",
       "      <td>1125.401855</td>\n",
       "      <td>50.375099</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>862.808105</td>\n",
       "      <td>...</td>\n",
       "      <td>57.877800</td>\n",
       "      <td>381.564789</td>\n",
       "      <td>936.763123</td>\n",
       "      <td>1.0718</td>\n",
       "      <td>646.302307</td>\n",
       "      <td>8094.319336</td>\n",
       "      <td>1083.601318</td>\n",
       "      <td>573.419128</td>\n",
       "      <td>30.010700</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-2J-AABA</th>\n",
       "      <td>99.345497</td>\n",
       "      <td>18.788200</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>99.276703</td>\n",
       "      <td>873.649597</td>\n",
       "      <td>10302.006836</td>\n",
       "      <td>633.161072</td>\n",
       "      <td>6.262700</td>\n",
       "      <td>18.7882</td>\n",
       "      <td>623.767029</td>\n",
       "      <td>...</td>\n",
       "      <td>52.606899</td>\n",
       "      <td>293.721588</td>\n",
       "      <td>1511.820923</td>\n",
       "      <td>1.2525</td>\n",
       "      <td>945.670898</td>\n",
       "      <td>4829.810547</td>\n",
       "      <td>1364.646851</td>\n",
       "      <td>793.486816</td>\n",
       "      <td>31.313601</td>\n",
       "      <td>0.6263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-2J-AABE</th>\n",
       "      <td>79.401901</td>\n",
       "      <td>3.083100</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>134.564499</td>\n",
       "      <td>74.610802</td>\n",
       "      <td>11076.861328</td>\n",
       "      <td>710.343811</td>\n",
       "      <td>35.147202</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>702.327698</td>\n",
       "      <td>...</td>\n",
       "      <td>56.728802</td>\n",
       "      <td>431.632507</td>\n",
       "      <td>1069.215454</td>\n",
       "      <td>0.6166</td>\n",
       "      <td>564.205322</td>\n",
       "      <td>7464.775879</td>\n",
       "      <td>832.434082</td>\n",
       "      <td>468.629608</td>\n",
       "      <td>48.096199</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 20501 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    A1BG       A1CF   A2BP1       A2LD1        A2ML1   \n",
       "TCGA-2J-AAB6   82.549698   8.187100  0.0000  163.122803  1815.789551  \\\n",
       "TCGA-2J-AAB8   56.930698  33.842499  0.0000  185.814301    16.921301   \n",
       "TCGA-2J-AAB9  105.787804  21.436199  1.0718  166.709503   642.015015   \n",
       "TCGA-2J-AABA   99.345497  18.788200  0.0000   99.276703   873.649597   \n",
       "TCGA-2J-AABE   79.401901   3.083100  0.0000  134.564499    74.610802   \n",
       "\n",
       "                       A2M       A4GALT      A4GNT     AAA1        AAAS  ...   \n",
       "TCGA-2J-AAB6   8517.444336  1121.052612   1.169600   1.1696  834.502930  ...  \\\n",
       "TCGA-2J-AAB8  14413.913086   392.949493   9.400700   0.9401  801.880127  ...   \n",
       "TCGA-2J-AAB9  24311.779297  1125.401855  50.375099   0.0000  862.808105  ...   \n",
       "TCGA-2J-AABA  10302.006836   633.161072   6.262700  18.7882  623.767029  ...   \n",
       "TCGA-2J-AABE  11076.861328   710.343811  35.147202   0.0000  702.327698  ...   \n",
       "\n",
       "                   ZXDA        ZXDB         ZXDC  ZYG11A      ZYG11B   \n",
       "TCGA-2J-AAB6  14.619900  269.005798  1053.216431  0.5848  683.625671  \\\n",
       "TCGA-2J-AAB8  35.722698  356.286713   829.142212  3.7603  680.611023   \n",
       "TCGA-2J-AAB9  57.877800  381.564789   936.763123  1.0718  646.302307   \n",
       "TCGA-2J-AABA  52.606899  293.721588  1511.820923  1.2525  945.670898   \n",
       "TCGA-2J-AABE  56.728802  431.632507  1069.215454  0.6166  564.205322   \n",
       "\n",
       "                       ZYX        ZZEF1        ZZZ3  psiTPTE22    tAKR  \n",
       "TCGA-2J-AAB6  11696.491211   869.005798  601.754395  26.315800  0.0000  \n",
       "TCGA-2J-AAB8   5829.377441   828.202087  609.165710  85.546402  0.0000  \n",
       "TCGA-2J-AAB9   8094.319336  1083.601318  573.419128  30.010700  0.0000  \n",
       "TCGA-2J-AABA   4829.810547  1364.646851  793.486816  31.313601  0.6263  \n",
       "TCGA-2J-AABE   7464.775879   832.434082  468.629608  48.096199  0.0000  \n",
       "\n",
       "[5 rows x 20501 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnaseq_data = pd.read_csv(settings.rnaseq_data_path, sep=\";\", index_col=0, decimal=\",\")\n",
    "rnaseq_data = rnaseq_data.T\n",
    "rnaseq_data = rnaseq_data.astype(np.float32)\n",
    "print(\"rnaseq_data.shape\", rnaseq_data.shape)\n",
    "rnaseq_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9f89678-93ce-419e-9d58-386a8d45026f",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = methylation_data.index.intersection(rnaseq_data.index)\n",
    "methylation_data = methylation_data.loc[samples]\n",
    "rnaseq_data = rnaseq_data.loc[samples]\n",
    "assert methylation_data.index.equals(rnaseq_data.index)\n",
    "\n",
    "methylation_train, methylation_val, rnaseq_train, rnaseq_val = train_test_split(methylation_data, rnaseq_data,\n",
    "                                                                                train_size= 0.6, random_state= settings.RANDOM_STATE)\n",
    "methylation_val, methylation_test, rnaseq_val, rnaseq_test = train_test_split(methylation_val, rnaseq_val,\n",
    "                                                                              train_size= 0.5, random_state= settings.RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ec9b551-22eb-408e-8cde-4f129fe4f4ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "methylation_data.shape (147, 301195)\n",
      "methylation_train.shape (88, 301195)\n",
      "methylation_val.shape (29, 301195)\n",
      "methylation_test.shape (30, 301195)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cg00000029</th>\n",
       "      <th>cg00000236</th>\n",
       "      <th>cg00000289</th>\n",
       "      <th>cg00000292</th>\n",
       "      <th>cg00000321</th>\n",
       "      <th>cg00000622</th>\n",
       "      <th>cg00000658</th>\n",
       "      <th>cg00000714</th>\n",
       "      <th>cg00000721</th>\n",
       "      <th>cg00000734</th>\n",
       "      <th>...</th>\n",
       "      <th>ch.9.2262725R</th>\n",
       "      <th>ch.9.2285199R</th>\n",
       "      <th>ch.9.2298007R</th>\n",
       "      <th>ch.9.2473665R</th>\n",
       "      <th>ch.9.357218F</th>\n",
       "      <th>ch.9.377428R</th>\n",
       "      <th>ch.9.691424R</th>\n",
       "      <th>ch.9.837340R</th>\n",
       "      <th>ch.9.898515R</th>\n",
       "      <th>ch.9.991104F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA-XD-AAUL</th>\n",
       "      <td>0.119118</td>\n",
       "      <td>0.837274</td>\n",
       "      <td>0.703877</td>\n",
       "      <td>0.697230</td>\n",
       "      <td>0.260051</td>\n",
       "      <td>0.016038</td>\n",
       "      <td>0.799700</td>\n",
       "      <td>0.116707</td>\n",
       "      <td>0.904165</td>\n",
       "      <td>0.061553</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053820</td>\n",
       "      <td>0.070162</td>\n",
       "      <td>0.024388</td>\n",
       "      <td>0.140970</td>\n",
       "      <td>0.077960</td>\n",
       "      <td>0.055053</td>\n",
       "      <td>0.131443</td>\n",
       "      <td>0.070289</td>\n",
       "      <td>0.088595</td>\n",
       "      <td>0.180667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-FB-AAPU</th>\n",
       "      <td>0.200873</td>\n",
       "      <td>0.860951</td>\n",
       "      <td>0.550535</td>\n",
       "      <td>0.685763</td>\n",
       "      <td>0.588282</td>\n",
       "      <td>0.015656</td>\n",
       "      <td>0.902761</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.942416</td>\n",
       "      <td>0.039498</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028646</td>\n",
       "      <td>0.037191</td>\n",
       "      <td>0.023118</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.092843</td>\n",
       "      <td>0.048249</td>\n",
       "      <td>0.072598</td>\n",
       "      <td>0.063718</td>\n",
       "      <td>0.055091</td>\n",
       "      <td>0.184036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-2L-AAQJ</th>\n",
       "      <td>0.243970</td>\n",
       "      <td>0.867054</td>\n",
       "      <td>0.655630</td>\n",
       "      <td>0.616977</td>\n",
       "      <td>0.558818</td>\n",
       "      <td>0.013877</td>\n",
       "      <td>0.839384</td>\n",
       "      <td>0.109439</td>\n",
       "      <td>0.943413</td>\n",
       "      <td>0.049919</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044160</td>\n",
       "      <td>0.040225</td>\n",
       "      <td>0.021784</td>\n",
       "      <td>0.136928</td>\n",
       "      <td>0.054368</td>\n",
       "      <td>0.035141</td>\n",
       "      <td>0.070832</td>\n",
       "      <td>0.046186</td>\n",
       "      <td>0.040649</td>\n",
       "      <td>0.121798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-IB-8127</th>\n",
       "      <td>0.298264</td>\n",
       "      <td>0.892158</td>\n",
       "      <td>0.732411</td>\n",
       "      <td>0.670695</td>\n",
       "      <td>0.307764</td>\n",
       "      <td>0.014719</td>\n",
       "      <td>0.821916</td>\n",
       "      <td>0.137486</td>\n",
       "      <td>0.952520</td>\n",
       "      <td>0.049755</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017009</td>\n",
       "      <td>0.039114</td>\n",
       "      <td>0.017551</td>\n",
       "      <td>0.068742</td>\n",
       "      <td>0.052975</td>\n",
       "      <td>0.036810</td>\n",
       "      <td>0.079168</td>\n",
       "      <td>0.041107</td>\n",
       "      <td>0.048051</td>\n",
       "      <td>0.106006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-FB-A5VM</th>\n",
       "      <td>0.270820</td>\n",
       "      <td>0.878813</td>\n",
       "      <td>0.534142</td>\n",
       "      <td>0.619671</td>\n",
       "      <td>0.296832</td>\n",
       "      <td>0.012052</td>\n",
       "      <td>0.886043</td>\n",
       "      <td>0.136257</td>\n",
       "      <td>0.937367</td>\n",
       "      <td>0.052111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020715</td>\n",
       "      <td>0.036642</td>\n",
       "      <td>0.023079</td>\n",
       "      <td>0.370927</td>\n",
       "      <td>0.034983</td>\n",
       "      <td>0.040559</td>\n",
       "      <td>0.051178</td>\n",
       "      <td>0.055982</td>\n",
       "      <td>0.051264</td>\n",
       "      <td>0.139150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 301195 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              cg00000029  cg00000236  cg00000289  cg00000292  cg00000321   \n",
       "TCGA-XD-AAUL    0.119118    0.837274    0.703877    0.697230    0.260051  \\\n",
       "TCGA-FB-AAPU    0.200873    0.860951    0.550535    0.685763    0.588282   \n",
       "TCGA-2L-AAQJ    0.243970    0.867054    0.655630    0.616977    0.558818   \n",
       "TCGA-IB-8127    0.298264    0.892158    0.732411    0.670695    0.307764   \n",
       "TCGA-FB-A5VM    0.270820    0.878813    0.534142    0.619671    0.296832   \n",
       "\n",
       "              cg00000622  cg00000658  cg00000714  cg00000721  cg00000734  ...   \n",
       "TCGA-XD-AAUL    0.016038    0.799700    0.116707    0.904165    0.061553  ...  \\\n",
       "TCGA-FB-AAPU    0.015656    0.902761    0.115385    0.942416    0.039498  ...   \n",
       "TCGA-2L-AAQJ    0.013877    0.839384    0.109439    0.943413    0.049919  ...   \n",
       "TCGA-IB-8127    0.014719    0.821916    0.137486    0.952520    0.049755  ...   \n",
       "TCGA-FB-A5VM    0.012052    0.886043    0.136257    0.937367    0.052111  ...   \n",
       "\n",
       "              ch.9.2262725R  ch.9.2285199R  ch.9.2298007R  ch.9.2473665R   \n",
       "TCGA-XD-AAUL       0.053820       0.070162       0.024388       0.140970  \\\n",
       "TCGA-FB-AAPU       0.028646       0.037191       0.023118            NaN   \n",
       "TCGA-2L-AAQJ       0.044160       0.040225       0.021784       0.136928   \n",
       "TCGA-IB-8127       0.017009       0.039114       0.017551       0.068742   \n",
       "TCGA-FB-A5VM       0.020715       0.036642       0.023079       0.370927   \n",
       "\n",
       "              ch.9.357218F  ch.9.377428R  ch.9.691424R  ch.9.837340R   \n",
       "TCGA-XD-AAUL      0.077960      0.055053      0.131443      0.070289  \\\n",
       "TCGA-FB-AAPU      0.092843      0.048249      0.072598      0.063718   \n",
       "TCGA-2L-AAQJ      0.054368      0.035141      0.070832      0.046186   \n",
       "TCGA-IB-8127      0.052975      0.036810      0.079168      0.041107   \n",
       "TCGA-FB-A5VM      0.034983      0.040559      0.051178      0.055982   \n",
       "\n",
       "              ch.9.898515R  ch.9.991104F  \n",
       "TCGA-XD-AAUL      0.088595      0.180667  \n",
       "TCGA-FB-AAPU      0.055091      0.184036  \n",
       "TCGA-2L-AAQJ      0.040649      0.121798  \n",
       "TCGA-IB-8127      0.048051      0.106006  \n",
       "TCGA-FB-A5VM      0.051264      0.139150  \n",
       "\n",
       "[5 rows x 301195 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"methylation_data.shape\", methylation_data.shape)\n",
    "print(\"methylation_train.shape\", methylation_train.shape)\n",
    "print(\"methylation_val.shape\", methylation_val.shape)\n",
    "print(\"methylation_test.shape\", methylation_test.shape)\n",
    "methylation_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb7cf855-d483-4ded-a9e5-1bb03fb2eaa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnaseq_data.shape (147, 20501)\n",
      "rnaseq_train.shape (88, 20501)\n",
      "rnaseq_val.shape (29, 20501)\n",
      "rnaseq_test.shape (30, 20501)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1BG</th>\n",
       "      <th>A1CF</th>\n",
       "      <th>A2BP1</th>\n",
       "      <th>A2LD1</th>\n",
       "      <th>A2ML1</th>\n",
       "      <th>A2M</th>\n",
       "      <th>A4GALT</th>\n",
       "      <th>A4GNT</th>\n",
       "      <th>AAA1</th>\n",
       "      <th>AAAS</th>\n",
       "      <th>...</th>\n",
       "      <th>ZXDA</th>\n",
       "      <th>ZXDB</th>\n",
       "      <th>ZXDC</th>\n",
       "      <th>ZYG11A</th>\n",
       "      <th>ZYG11B</th>\n",
       "      <th>ZYX</th>\n",
       "      <th>ZZEF1</th>\n",
       "      <th>ZZZ3</th>\n",
       "      <th>psiTPTE22</th>\n",
       "      <th>tAKR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA-XD-AAUL</th>\n",
       "      <td>101.975098</td>\n",
       "      <td>89.397102</td>\n",
       "      <td>0.8316</td>\n",
       "      <td>67.430397</td>\n",
       "      <td>12.889800</td>\n",
       "      <td>22677.654297</td>\n",
       "      <td>1000.415771</td>\n",
       "      <td>20.790001</td>\n",
       "      <td>3.3264</td>\n",
       "      <td>648.232788</td>\n",
       "      <td>...</td>\n",
       "      <td>49.480202</td>\n",
       "      <td>417.463593</td>\n",
       "      <td>924.740112</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>709.355530</td>\n",
       "      <td>11670.686523</td>\n",
       "      <td>922.245300</td>\n",
       "      <td>505.613312</td>\n",
       "      <td>38.669399</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-FB-AAPU</th>\n",
       "      <td>29.661301</td>\n",
       "      <td>176.090393</td>\n",
       "      <td>1.5018</td>\n",
       "      <td>209.326004</td>\n",
       "      <td>2.252800</td>\n",
       "      <td>6172.876465</td>\n",
       "      <td>82.976501</td>\n",
       "      <td>84.102898</td>\n",
       "      <td>3.0037</td>\n",
       "      <td>574.452576</td>\n",
       "      <td>...</td>\n",
       "      <td>52.564301</td>\n",
       "      <td>591.348328</td>\n",
       "      <td>976.193970</td>\n",
       "      <td>0.3755</td>\n",
       "      <td>607.492981</td>\n",
       "      <td>5116.007324</td>\n",
       "      <td>1777.799561</td>\n",
       "      <td>552.300476</td>\n",
       "      <td>11.639200</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-2L-AAQJ</th>\n",
       "      <td>91.529701</td>\n",
       "      <td>17.821800</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>82.044601</td>\n",
       "      <td>1.980200</td>\n",
       "      <td>15670.208008</td>\n",
       "      <td>1068.316772</td>\n",
       "      <td>214.356400</td>\n",
       "      <td>0.9901</td>\n",
       "      <td>499.505005</td>\n",
       "      <td>...</td>\n",
       "      <td>52.475201</td>\n",
       "      <td>409.405914</td>\n",
       "      <td>920.792114</td>\n",
       "      <td>1.4851</td>\n",
       "      <td>525.742615</td>\n",
       "      <td>5813.861328</td>\n",
       "      <td>842.574280</td>\n",
       "      <td>454.455414</td>\n",
       "      <td>19.306900</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-IB-8127</th>\n",
       "      <td>58.019798</td>\n",
       "      <td>49.472301</td>\n",
       "      <td>1.2951</td>\n",
       "      <td>84.390297</td>\n",
       "      <td>211.098907</td>\n",
       "      <td>13915.374023</td>\n",
       "      <td>704.785278</td>\n",
       "      <td>6.475400</td>\n",
       "      <td>0.7771</td>\n",
       "      <td>596.516174</td>\n",
       "      <td>...</td>\n",
       "      <td>42.737801</td>\n",
       "      <td>483.325806</td>\n",
       "      <td>758.401917</td>\n",
       "      <td>0.2590</td>\n",
       "      <td>587.968689</td>\n",
       "      <td>4527.099609</td>\n",
       "      <td>882.729980</td>\n",
       "      <td>600.142517</td>\n",
       "      <td>59.055901</td>\n",
       "      <td>0.2590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-FB-A5VM</th>\n",
       "      <td>140.865906</td>\n",
       "      <td>5.216500</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>138.534195</td>\n",
       "      <td>810.119995</td>\n",
       "      <td>16176.593750</td>\n",
       "      <td>6401.669434</td>\n",
       "      <td>1.043300</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>796.557129</td>\n",
       "      <td>...</td>\n",
       "      <td>17.214399</td>\n",
       "      <td>182.055298</td>\n",
       "      <td>1124.673950</td>\n",
       "      <td>2.0866</td>\n",
       "      <td>376.108490</td>\n",
       "      <td>10555.555664</td>\n",
       "      <td>704.225403</td>\n",
       "      <td>394.366211</td>\n",
       "      <td>18.779301</td>\n",
       "      <td>1.0433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 20501 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    A1BG        A1CF   A2BP1       A2LD1       A2ML1   \n",
       "TCGA-XD-AAUL  101.975098   89.397102  0.8316   67.430397   12.889800  \\\n",
       "TCGA-FB-AAPU   29.661301  176.090393  1.5018  209.326004    2.252800   \n",
       "TCGA-2L-AAQJ   91.529701   17.821800  0.0000   82.044601    1.980200   \n",
       "TCGA-IB-8127   58.019798   49.472301  1.2951   84.390297  211.098907   \n",
       "TCGA-FB-A5VM  140.865906    5.216500  0.0000  138.534195  810.119995   \n",
       "\n",
       "                       A2M       A4GALT       A4GNT    AAA1        AAAS  ...   \n",
       "TCGA-XD-AAUL  22677.654297  1000.415771   20.790001  3.3264  648.232788  ...  \\\n",
       "TCGA-FB-AAPU   6172.876465    82.976501   84.102898  3.0037  574.452576  ...   \n",
       "TCGA-2L-AAQJ  15670.208008  1068.316772  214.356400  0.9901  499.505005  ...   \n",
       "TCGA-IB-8127  13915.374023   704.785278    6.475400  0.7771  596.516174  ...   \n",
       "TCGA-FB-A5VM  16176.593750  6401.669434    1.043300  0.0000  796.557129  ...   \n",
       "\n",
       "                   ZXDA        ZXDB         ZXDC  ZYG11A      ZYG11B   \n",
       "TCGA-XD-AAUL  49.480202  417.463593   924.740112  0.0000  709.355530  \\\n",
       "TCGA-FB-AAPU  52.564301  591.348328   976.193970  0.3755  607.492981   \n",
       "TCGA-2L-AAQJ  52.475201  409.405914   920.792114  1.4851  525.742615   \n",
       "TCGA-IB-8127  42.737801  483.325806   758.401917  0.2590  587.968689   \n",
       "TCGA-FB-A5VM  17.214399  182.055298  1124.673950  2.0866  376.108490   \n",
       "\n",
       "                       ZYX        ZZEF1        ZZZ3  psiTPTE22    tAKR  \n",
       "TCGA-XD-AAUL  11670.686523   922.245300  505.613312  38.669399  0.0000  \n",
       "TCGA-FB-AAPU   5116.007324  1777.799561  552.300476  11.639200  0.0000  \n",
       "TCGA-2L-AAQJ   5813.861328   842.574280  454.455414  19.306900  0.0000  \n",
       "TCGA-IB-8127   4527.099609   882.729980  600.142517  59.055901  0.2590  \n",
       "TCGA-FB-A5VM  10555.555664   704.225403  394.366211  18.779301  1.0433  \n",
       "\n",
       "[5 rows x 20501 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"rnaseq_data.shape\", rnaseq_data.shape)\n",
    "print(\"rnaseq_train.shape\", rnaseq_train.shape)\n",
    "print(\"rnaseq_val.shape\", rnaseq_val.shape)\n",
    "print(\"rnaseq_test.shape\", rnaseq_test.shape)\n",
    "rnaseq_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7eb6a7dd-df0c-4de5-92b1-c9846585413a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RemovePatientsWithZeros keeping 17138 features\n",
      "RemoveFeaturesLowMAE keeping 8569 features\n",
      "RemoveCorrelatedFeatures keeping 6904 features\n",
      "FeatureSelectionNMF keeping 150 features\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;removepatientswithzeros&#x27;,\n",
       "                 RemovePatientsWithZeros(verbose=True)),\n",
       "                (&#x27;removefeatureslowmae&#x27;,\n",
       "                 RemoveFeaturesLowMAE(percentage_to_keep=0.5, verbose=True)),\n",
       "                (&#x27;removecorrelatedfeatures&#x27;,\n",
       "                 RemoveCorrelatedFeatures(threshold=0.85, verbose=True)),\n",
       "                (&#x27;functiontransformer&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x7faabfb352d0&gt;)),\n",
       "                (&#x27;featureselectionnmf&#x27;,\n",
       "                 FeatureSelectionNMF(n_largest=3,\n",
       "                                     nmf=NMF(max_iter=500, n_components=50,\n",
       "                                             random_state=42),\n",
       "                                     verbose=True)),\n",
       "                (&#x27;standardscaler&#x27;, StandardScaler())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;removepatientswithzeros&#x27;,\n",
       "                 RemovePatientsWithZeros(verbose=True)),\n",
       "                (&#x27;removefeatureslowmae&#x27;,\n",
       "                 RemoveFeaturesLowMAE(percentage_to_keep=0.5, verbose=True)),\n",
       "                (&#x27;removecorrelatedfeatures&#x27;,\n",
       "                 RemoveCorrelatedFeatures(threshold=0.85, verbose=True)),\n",
       "                (&#x27;functiontransformer&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x7faabfb352d0&gt;)),\n",
       "                (&#x27;featureselectionnmf&#x27;,\n",
       "                 FeatureSelectionNMF(n_largest=3,\n",
       "                                     nmf=NMF(max_iter=500, n_components=50,\n",
       "                                             random_state=42),\n",
       "                                     verbose=True)),\n",
       "                (&#x27;standardscaler&#x27;, StandardScaler())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RemovePatientsWithZeros</label><div class=\"sk-toggleable__content\"><pre>RemovePatientsWithZeros(verbose=True)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RemoveFeaturesLowMAE</label><div class=\"sk-toggleable__content\"><pre>RemoveFeaturesLowMAE(percentage_to_keep=0.5, verbose=True)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RemoveCorrelatedFeatures</label><div class=\"sk-toggleable__content\"><pre>RemoveCorrelatedFeatures(threshold=0.85, verbose=True)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x7faabfb352d0&gt;)</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">featureselectionnmf: FeatureSelectionNMF</label><div class=\"sk-toggleable__content\"><pre>FeatureSelectionNMF(n_largest=3,\n",
       "                    nmf=NMF(max_iter=500, n_components=50, random_state=42),\n",
       "                    verbose=True)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">nmf: NMF</label><div class=\"sk-toggleable__content\"><pre>NMF(max_iter=500, n_components=50, random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NMF</label><div class=\"sk-toggleable__content\"><pre>NMF(max_iter=500, n_components=50, random_state=42)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('removepatientswithzeros',\n",
       "                 RemovePatientsWithZeros(verbose=True)),\n",
       "                ('removefeatureslowmae',\n",
       "                 RemoveFeaturesLowMAE(percentage_to_keep=0.5, verbose=True)),\n",
       "                ('removecorrelatedfeatures',\n",
       "                 RemoveCorrelatedFeatures(threshold=0.85, verbose=True)),\n",
       "                ('functiontransformer',\n",
       "                 FunctionTransformer(func=<function <lambda> at 0x7faabfb352d0>)),\n",
       "                ('featureselectionnmf',\n",
       "                 FeatureSelectionNMF(n_largest=3,\n",
       "                                     nmf=NMF(max_iter=500, n_components=50,\n",
       "                                             random_state=42),\n",
       "                                     verbose=True)),\n",
       "                ('standardscaler', StandardScaler())])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnaseq_pipeline = make_pipeline(\n",
    "    RemovePatientsWithZeros(threshold= 0.2, verbose= True),\n",
    "    RemoveFeaturesLowMAE(percentage_to_keep= 0.5, verbose= True),\n",
    "    RemoveCorrelatedFeatures(threshold = 0.85, verbose= True),\n",
    "    FunctionTransformer(lambda x: np.log2(1 + x)),\n",
    "    FeatureSelectionNMF(nmf = NMF(n_components= 50, max_iter=500, random_state=settings.RANDOM_STATE), n_largest= 3, verbose= True),\n",
    "    StandardScaler().set_output(transform= 'pandas'),\n",
    ")\n",
    "rnaseq_pipeline.fit(rnaseq_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb98ff57-b96b-46ef-b65b-e4da5a5a4830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformed_rnaseq_train.shape (88, 150)\n",
      "transformed_rnaseq_val.shape (29, 150)\n",
      "transformed_rnaseq_test.shape (30, 150)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACTB</th>\n",
       "      <th>ACTG1</th>\n",
       "      <th>ALPPL2</th>\n",
       "      <th>ANXA10</th>\n",
       "      <th>AQP5</th>\n",
       "      <th>AREG</th>\n",
       "      <th>C12orf36</th>\n",
       "      <th>C20orf114</th>\n",
       "      <th>CA9</th>\n",
       "      <th>CAPN9</th>\n",
       "      <th>...</th>\n",
       "      <th>TNS4</th>\n",
       "      <th>TPT1</th>\n",
       "      <th>UCA1</th>\n",
       "      <th>UGT1A10</th>\n",
       "      <th>UGT1A6</th>\n",
       "      <th>UPK1B</th>\n",
       "      <th>VIL1</th>\n",
       "      <th>VSIG1</th>\n",
       "      <th>WNT11</th>\n",
       "      <th>XIST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA-XD-AAUL</th>\n",
       "      <td>1.377711</td>\n",
       "      <td>1.283202</td>\n",
       "      <td>0.873771</td>\n",
       "      <td>0.530496</td>\n",
       "      <td>0.698241</td>\n",
       "      <td>1.268197</td>\n",
       "      <td>1.112528</td>\n",
       "      <td>1.667222</td>\n",
       "      <td>-0.390824</td>\n",
       "      <td>0.885736</td>\n",
       "      <td>...</td>\n",
       "      <td>0.422731</td>\n",
       "      <td>-0.873962</td>\n",
       "      <td>1.296716</td>\n",
       "      <td>0.825211</td>\n",
       "      <td>0.978526</td>\n",
       "      <td>0.901230</td>\n",
       "      <td>1.232005</td>\n",
       "      <td>0.786613</td>\n",
       "      <td>-0.480438</td>\n",
       "      <td>-0.955095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-FB-AAPU</th>\n",
       "      <td>0.089504</td>\n",
       "      <td>3.073718</td>\n",
       "      <td>-0.299647</td>\n",
       "      <td>1.304117</td>\n",
       "      <td>-2.274756</td>\n",
       "      <td>-0.188027</td>\n",
       "      <td>0.136100</td>\n",
       "      <td>0.827431</td>\n",
       "      <td>0.151547</td>\n",
       "      <td>0.530010</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.990722</td>\n",
       "      <td>0.776639</td>\n",
       "      <td>-0.637404</td>\n",
       "      <td>0.575526</td>\n",
       "      <td>-0.557144</td>\n",
       "      <td>-0.428184</td>\n",
       "      <td>1.503575</td>\n",
       "      <td>1.130367</td>\n",
       "      <td>-1.698521</td>\n",
       "      <td>1.114916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-2L-AAQJ</th>\n",
       "      <td>0.627867</td>\n",
       "      <td>1.462564</td>\n",
       "      <td>0.111647</td>\n",
       "      <td>0.923410</td>\n",
       "      <td>1.154292</td>\n",
       "      <td>0.515806</td>\n",
       "      <td>1.083329</td>\n",
       "      <td>1.311565</td>\n",
       "      <td>-0.684323</td>\n",
       "      <td>1.315569</td>\n",
       "      <td>...</td>\n",
       "      <td>1.678476</td>\n",
       "      <td>0.633906</td>\n",
       "      <td>-0.173739</td>\n",
       "      <td>0.593691</td>\n",
       "      <td>0.588944</td>\n",
       "      <td>0.493590</td>\n",
       "      <td>1.152439</td>\n",
       "      <td>1.260442</td>\n",
       "      <td>0.146435</td>\n",
       "      <td>0.860770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-IB-8127</th>\n",
       "      <td>-0.963819</td>\n",
       "      <td>-1.721784</td>\n",
       "      <td>1.068385</td>\n",
       "      <td>0.596719</td>\n",
       "      <td>-0.021600</td>\n",
       "      <td>0.923351</td>\n",
       "      <td>1.317930</td>\n",
       "      <td>-0.979773</td>\n",
       "      <td>-1.091449</td>\n",
       "      <td>0.497105</td>\n",
       "      <td>...</td>\n",
       "      <td>0.538557</td>\n",
       "      <td>-1.537145</td>\n",
       "      <td>0.528642</td>\n",
       "      <td>1.085053</td>\n",
       "      <td>0.185827</td>\n",
       "      <td>-0.764921</td>\n",
       "      <td>1.004616</td>\n",
       "      <td>-1.130930</td>\n",
       "      <td>1.595554</td>\n",
       "      <td>-0.846630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-FB-A5VM</th>\n",
       "      <td>0.621693</td>\n",
       "      <td>1.637324</td>\n",
       "      <td>0.000703</td>\n",
       "      <td>-2.783494</td>\n",
       "      <td>0.420245</td>\n",
       "      <td>1.212379</td>\n",
       "      <td>-2.287281</td>\n",
       "      <td>0.772808</td>\n",
       "      <td>-1.326160</td>\n",
       "      <td>-1.977437</td>\n",
       "      <td>...</td>\n",
       "      <td>1.145301</td>\n",
       "      <td>0.075263</td>\n",
       "      <td>-0.012212</td>\n",
       "      <td>0.273243</td>\n",
       "      <td>0.530534</td>\n",
       "      <td>1.518022</td>\n",
       "      <td>-2.981772</td>\n",
       "      <td>-2.066809</td>\n",
       "      <td>0.878491</td>\n",
       "      <td>-0.643601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ACTB     ACTG1    ALPPL2    ANXA10      AQP5      AREG   \n",
       "TCGA-XD-AAUL  1.377711  1.283202  0.873771  0.530496  0.698241  1.268197  \\\n",
       "TCGA-FB-AAPU  0.089504  3.073718 -0.299647  1.304117 -2.274756 -0.188027   \n",
       "TCGA-2L-AAQJ  0.627867  1.462564  0.111647  0.923410  1.154292  0.515806   \n",
       "TCGA-IB-8127 -0.963819 -1.721784  1.068385  0.596719 -0.021600  0.923351   \n",
       "TCGA-FB-A5VM  0.621693  1.637324  0.000703 -2.783494  0.420245  1.212379   \n",
       "\n",
       "              C12orf36  C20orf114       CA9     CAPN9  ...      TNS4   \n",
       "TCGA-XD-AAUL  1.112528   1.667222 -0.390824  0.885736  ...  0.422731  \\\n",
       "TCGA-FB-AAPU  0.136100   0.827431  0.151547  0.530010  ... -0.990722   \n",
       "TCGA-2L-AAQJ  1.083329   1.311565 -0.684323  1.315569  ...  1.678476   \n",
       "TCGA-IB-8127  1.317930  -0.979773 -1.091449  0.497105  ...  0.538557   \n",
       "TCGA-FB-A5VM -2.287281   0.772808 -1.326160 -1.977437  ...  1.145301   \n",
       "\n",
       "                  TPT1      UCA1   UGT1A10    UGT1A6     UPK1B      VIL1   \n",
       "TCGA-XD-AAUL -0.873962  1.296716  0.825211  0.978526  0.901230  1.232005  \\\n",
       "TCGA-FB-AAPU  0.776639 -0.637404  0.575526 -0.557144 -0.428184  1.503575   \n",
       "TCGA-2L-AAQJ  0.633906 -0.173739  0.593691  0.588944  0.493590  1.152439   \n",
       "TCGA-IB-8127 -1.537145  0.528642  1.085053  0.185827 -0.764921  1.004616   \n",
       "TCGA-FB-A5VM  0.075263 -0.012212  0.273243  0.530534  1.518022 -2.981772   \n",
       "\n",
       "                 VSIG1     WNT11      XIST  \n",
       "TCGA-XD-AAUL  0.786613 -0.480438 -0.955095  \n",
       "TCGA-FB-AAPU  1.130367 -1.698521  1.114916  \n",
       "TCGA-2L-AAQJ  1.260442  0.146435  0.860770  \n",
       "TCGA-IB-8127 -1.130930  1.595554 -0.846630  \n",
       "TCGA-FB-A5VM -2.066809  0.878491 -0.643601  \n",
       "\n",
       "[5 rows x 150 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_rnaseq_train = rnaseq_pipeline.transform(rnaseq_train)\n",
    "transformed_rnaseq_val = rnaseq_pipeline.transform(rnaseq_val)\n",
    "transformed_rnaseq_test = rnaseq_pipeline.transform(rnaseq_test)\n",
    "print(\"transformed_rnaseq_train.shape\", transformed_rnaseq_train.shape)\n",
    "print(\"transformed_rnaseq_val.shape\", transformed_rnaseq_val.shape)\n",
    "print(\"transformed_rnaseq_test.shape\", transformed_rnaseq_test.shape)\n",
    "transformed_rnaseq_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d6bad2f-d1d8-492b-a50c-e3ddee6080dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RemovePatientsWithNaN keeping 300944 features\n",
      "RemoveFeaturesLowMAE keeping 30094 features\n",
      "FeatureSelectionNMF keeping 250 features\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;removepatientswithnan&#x27;, RemovePatientsWithNaN(verbose=True)),\n",
       "                (&#x27;removefeatureslowmae&#x27;,\n",
       "                 RemoveFeaturesLowMAE(percentage_to_keep=0.1, verbose=True)),\n",
       "                (&#x27;simpleimputer&#x27;, SimpleImputer()),\n",
       "                (&#x27;featureselectionnmf&#x27;,\n",
       "                 FeatureSelectionNMF(n_largest=10,\n",
       "                                     nmf=NMF(max_iter=1000, n_components=25,\n",
       "                                             random_state=42),\n",
       "                                     verbose=True)),\n",
       "                (&#x27;standardscaler&#x27;, StandardScaler())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;removepatientswithnan&#x27;, RemovePatientsWithNaN(verbose=True)),\n",
       "                (&#x27;removefeatureslowmae&#x27;,\n",
       "                 RemoveFeaturesLowMAE(percentage_to_keep=0.1, verbose=True)),\n",
       "                (&#x27;simpleimputer&#x27;, SimpleImputer()),\n",
       "                (&#x27;featureselectionnmf&#x27;,\n",
       "                 FeatureSelectionNMF(n_largest=10,\n",
       "                                     nmf=NMF(max_iter=1000, n_components=25,\n",
       "                                             random_state=42),\n",
       "                                     verbose=True)),\n",
       "                (&#x27;standardscaler&#x27;, StandardScaler())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RemovePatientsWithNaN</label><div class=\"sk-toggleable__content\"><pre>RemovePatientsWithNaN(verbose=True)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RemoveFeaturesLowMAE</label><div class=\"sk-toggleable__content\"><pre>RemoveFeaturesLowMAE(percentage_to_keep=0.1, verbose=True)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">featureselectionnmf: FeatureSelectionNMF</label><div class=\"sk-toggleable__content\"><pre>FeatureSelectionNMF(n_largest=10,\n",
       "                    nmf=NMF(max_iter=1000, n_components=25, random_state=42),\n",
       "                    verbose=True)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">nmf: NMF</label><div class=\"sk-toggleable__content\"><pre>NMF(max_iter=1000, n_components=25, random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NMF</label><div class=\"sk-toggleable__content\"><pre>NMF(max_iter=1000, n_components=25, random_state=42)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('removepatientswithnan', RemovePatientsWithNaN(verbose=True)),\n",
       "                ('removefeatureslowmae',\n",
       "                 RemoveFeaturesLowMAE(percentage_to_keep=0.1, verbose=True)),\n",
       "                ('simpleimputer', SimpleImputer()),\n",
       "                ('featureselectionnmf',\n",
       "                 FeatureSelectionNMF(n_largest=10,\n",
       "                                     nmf=NMF(max_iter=1000, n_components=25,\n",
       "                                             random_state=42),\n",
       "                                     verbose=True)),\n",
       "                ('standardscaler', StandardScaler())])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "methylation_pipeline = make_pipeline(\n",
    "    RemovePatientsWithNaN(threshold = 0.2, verbose= True),\n",
    "    RemoveFeaturesLowMAE(percentage_to_keep= 0.1, verbose= True),\n",
    "    # RemoveCorrelatedFeatures(threshold = 0.85, verbose= True),\n",
    "    SimpleImputer(strategy= \"mean\").set_output(transform= 'pandas'),\n",
    "    FeatureSelectionNMF(nmf = NMF(n_components= 25, max_iter=1000, random_state=settings.RANDOM_STATE), n_largest= 10, verbose= True),\n",
    "    StandardScaler().set_output(transform= 'pandas'),\n",
    ")\n",
    "methylation_pipeline.fit(methylation_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d24c31ff-c72c-465f-9b06-1a20e2c6503e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformed_methylation_train.shape (88, 250)\n",
      "transformed_methylation_val.shape (29, 250)\n",
      "transformed_methylation_test.shape (30, 250)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cg00208274</th>\n",
       "      <th>cg00211215</th>\n",
       "      <th>cg00219169</th>\n",
       "      <th>cg00263677</th>\n",
       "      <th>cg00277165</th>\n",
       "      <th>cg00288598</th>\n",
       "      <th>cg00407546</th>\n",
       "      <th>cg00429618</th>\n",
       "      <th>cg00590063</th>\n",
       "      <th>cg00590260</th>\n",
       "      <th>...</th>\n",
       "      <th>cg26896255</th>\n",
       "      <th>cg26927232</th>\n",
       "      <th>cg26975184</th>\n",
       "      <th>cg27215100</th>\n",
       "      <th>cg27215768</th>\n",
       "      <th>cg27363327</th>\n",
       "      <th>cg27436995</th>\n",
       "      <th>cg27518014</th>\n",
       "      <th>cg27519330</th>\n",
       "      <th>cg27648858</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA-XD-AAUL</th>\n",
       "      <td>-0.688709</td>\n",
       "      <td>-1.713840</td>\n",
       "      <td>-1.278498</td>\n",
       "      <td>-0.536602</td>\n",
       "      <td>-0.848910</td>\n",
       "      <td>-0.638789</td>\n",
       "      <td>-6.816996e-01</td>\n",
       "      <td>-0.577057</td>\n",
       "      <td>0.346054</td>\n",
       "      <td>-0.543163</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.366749</td>\n",
       "      <td>-0.639702</td>\n",
       "      <td>-1.992672</td>\n",
       "      <td>0.330675</td>\n",
       "      <td>-0.593425</td>\n",
       "      <td>-1.015105</td>\n",
       "      <td>-0.619884</td>\n",
       "      <td>0.706562</td>\n",
       "      <td>-1.733402</td>\n",
       "      <td>0.651739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-FB-AAPU</th>\n",
       "      <td>-1.945872</td>\n",
       "      <td>0.059582</td>\n",
       "      <td>1.164786</td>\n",
       "      <td>1.248130</td>\n",
       "      <td>1.556380</td>\n",
       "      <td>-0.187517</td>\n",
       "      <td>-9.436164e-08</td>\n",
       "      <td>0.236874</td>\n",
       "      <td>1.031779</td>\n",
       "      <td>1.022741</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.167560</td>\n",
       "      <td>1.044713</td>\n",
       "      <td>1.264647</td>\n",
       "      <td>1.031804</td>\n",
       "      <td>-1.305447</td>\n",
       "      <td>2.015486</td>\n",
       "      <td>0.844234</td>\n",
       "      <td>0.543468</td>\n",
       "      <td>0.875695</td>\n",
       "      <td>-1.382316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-2L-AAQJ</th>\n",
       "      <td>-0.327782</td>\n",
       "      <td>0.910073</td>\n",
       "      <td>0.521873</td>\n",
       "      <td>0.856129</td>\n",
       "      <td>-0.348680</td>\n",
       "      <td>-0.755197</td>\n",
       "      <td>1.126507e+00</td>\n",
       "      <td>-0.097786</td>\n",
       "      <td>0.191459</td>\n",
       "      <td>0.258920</td>\n",
       "      <td>...</td>\n",
       "      <td>0.512767</td>\n",
       "      <td>-0.677124</td>\n",
       "      <td>0.742915</td>\n",
       "      <td>0.164681</td>\n",
       "      <td>-0.854530</td>\n",
       "      <td>-0.489627</td>\n",
       "      <td>0.865560</td>\n",
       "      <td>-1.458948</td>\n",
       "      <td>0.603482</td>\n",
       "      <td>0.211613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-IB-8127</th>\n",
       "      <td>0.195839</td>\n",
       "      <td>0.975029</td>\n",
       "      <td>1.451579</td>\n",
       "      <td>0.238453</td>\n",
       "      <td>-0.191673</td>\n",
       "      <td>0.125288</td>\n",
       "      <td>2.100167e+00</td>\n",
       "      <td>-0.551763</td>\n",
       "      <td>1.021747</td>\n",
       "      <td>1.545342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741228</td>\n",
       "      <td>0.052672</td>\n",
       "      <td>-0.566946</td>\n",
       "      <td>0.389151</td>\n",
       "      <td>-0.499596</td>\n",
       "      <td>1.080622</td>\n",
       "      <td>1.275766</td>\n",
       "      <td>0.506148</td>\n",
       "      <td>0.146393</td>\n",
       "      <td>-0.396684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-FB-A5VM</th>\n",
       "      <td>-0.310788</td>\n",
       "      <td>-0.347750</td>\n",
       "      <td>0.144406</td>\n",
       "      <td>0.289688</td>\n",
       "      <td>-1.079381</td>\n",
       "      <td>-0.666001</td>\n",
       "      <td>7.285536e-01</td>\n",
       "      <td>2.040396</td>\n",
       "      <td>-1.006759</td>\n",
       "      <td>-0.516435</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.278436</td>\n",
       "      <td>1.507968</td>\n",
       "      <td>0.466626</td>\n",
       "      <td>-0.950118</td>\n",
       "      <td>0.749941</td>\n",
       "      <td>-0.975773</td>\n",
       "      <td>-0.172302</td>\n",
       "      <td>0.636899</td>\n",
       "      <td>1.076045</td>\n",
       "      <td>2.073017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 250 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              cg00208274  cg00211215  cg00219169  cg00263677  cg00277165   \n",
       "TCGA-XD-AAUL   -0.688709   -1.713840   -1.278498   -0.536602   -0.848910  \\\n",
       "TCGA-FB-AAPU   -1.945872    0.059582    1.164786    1.248130    1.556380   \n",
       "TCGA-2L-AAQJ   -0.327782    0.910073    0.521873    0.856129   -0.348680   \n",
       "TCGA-IB-8127    0.195839    0.975029    1.451579    0.238453   -0.191673   \n",
       "TCGA-FB-A5VM   -0.310788   -0.347750    0.144406    0.289688   -1.079381   \n",
       "\n",
       "              cg00288598    cg00407546  cg00429618  cg00590063  cg00590260   \n",
       "TCGA-XD-AAUL   -0.638789 -6.816996e-01   -0.577057    0.346054   -0.543163  \\\n",
       "TCGA-FB-AAPU   -0.187517 -9.436164e-08    0.236874    1.031779    1.022741   \n",
       "TCGA-2L-AAQJ   -0.755197  1.126507e+00   -0.097786    0.191459    0.258920   \n",
       "TCGA-IB-8127    0.125288  2.100167e+00   -0.551763    1.021747    1.545342   \n",
       "TCGA-FB-A5VM   -0.666001  7.285536e-01    2.040396   -1.006759   -0.516435   \n",
       "\n",
       "              ...  cg26896255  cg26927232  cg26975184  cg27215100  cg27215768   \n",
       "TCGA-XD-AAUL  ...   -0.366749   -0.639702   -1.992672    0.330675   -0.593425  \\\n",
       "TCGA-FB-AAPU  ...   -1.167560    1.044713    1.264647    1.031804   -1.305447   \n",
       "TCGA-2L-AAQJ  ...    0.512767   -0.677124    0.742915    0.164681   -0.854530   \n",
       "TCGA-IB-8127  ...    0.741228    0.052672   -0.566946    0.389151   -0.499596   \n",
       "TCGA-FB-A5VM  ...   -1.278436    1.507968    0.466626   -0.950118    0.749941   \n",
       "\n",
       "              cg27363327  cg27436995  cg27518014  cg27519330  cg27648858  \n",
       "TCGA-XD-AAUL   -1.015105   -0.619884    0.706562   -1.733402    0.651739  \n",
       "TCGA-FB-AAPU    2.015486    0.844234    0.543468    0.875695   -1.382316  \n",
       "TCGA-2L-AAQJ   -0.489627    0.865560   -1.458948    0.603482    0.211613  \n",
       "TCGA-IB-8127    1.080622    1.275766    0.506148    0.146393   -0.396684  \n",
       "TCGA-FB-A5VM   -0.975773   -0.172302    0.636899    1.076045    2.073017  \n",
       "\n",
       "[5 rows x 250 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_methylation_train = methylation_pipeline.transform(methylation_train)\n",
    "transformed_methylation_val = methylation_pipeline.transform(methylation_val)\n",
    "transformed_methylation_test = methylation_pipeline.transform(methylation_test)\n",
    "print(\"transformed_methylation_train.shape\", transformed_methylation_train.shape)\n",
    "print(\"transformed_methylation_val.shape\", transformed_methylation_val.shape)\n",
    "print(\"transformed_methylation_test.shape\", transformed_methylation_test.shape)\n",
    "transformed_methylation_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abca288e-a500-4962-87e1-b2f8d0787566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[250, 250]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xs_train = [transformed_methylation_train, transformed_methylation_train]\n",
    "Xs_val = [transformed_rnaseq_val, transformed_methylation_val]\n",
    "Xs_test = [transformed_rnaseq_test, transformed_methylation_test]\n",
    "in_channels_list = [X.shape[1] for X in Xs_train]\n",
    "in_channels_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10349f42-692e-46b1-8d2a-4074df04218b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MVAutoencoder(\n",
       "  (encoder_0): MLP(\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (hidden_0): Sequential(\n",
       "      (0): Linear(in_features=250, out_features=50, bias=True)\n",
       "      (1): ADN(\n",
       "        (N): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (A): PReLU(num_parameters=1)\n",
       "      )\n",
       "    )\n",
       "    (output): Linear(in_features=50, out_features=50, bias=True)\n",
       "  )\n",
       "  (decoder_0): MLP(\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (hidden_0): Sequential(\n",
       "      (0): Linear(in_features=100, out_features=50, bias=True)\n",
       "      (1): ADN(\n",
       "        (N): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (A): PReLU(num_parameters=1)\n",
       "      )\n",
       "    )\n",
       "    (output): Linear(in_features=50, out_features=250, bias=True)\n",
       "  )\n",
       "  (encoder_1): MLP(\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (hidden_0): Sequential(\n",
       "      (0): Linear(in_features=250, out_features=50, bias=True)\n",
       "      (1): ADN(\n",
       "        (N): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (A): PReLU(num_parameters=1)\n",
       "      )\n",
       "    )\n",
       "    (output): Linear(in_features=50, out_features=50, bias=True)\n",
       "  )\n",
       "  (decoder_1): MLP(\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (hidden_0): Sequential(\n",
       "      (0): Linear(in_features=100, out_features=50, bias=True)\n",
       "      (1): ADN(\n",
       "        (N): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (A): PReLU(num_parameters=1)\n",
       "      )\n",
       "    )\n",
       "    (output): Linear(in_features=50, out_features=250, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MVAutoencoder(in_channels_list= in_channels_list, out_channels= 50, hidden_channels_list = [[i//5] for i in in_channels_list])\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4fceb503-3ffd-4522-8881-90850466d25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = MultiViewDataset(Xs= Xs_train)\n",
    "validation_data = MultiViewDataset(Xs= Xs_val)\n",
    "testing_data = MultiViewDataset(Xs= Xs_test)\n",
    "\n",
    "train_dataloader = DataLoader(dataset= training_data , batch_size=32, shuffle=True)\n",
    "val_dataloader = DataLoader(dataset= validation_data , batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(dataset= testing_data , batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb91b6e5-e433-406b-bb09-136844220e30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 1.6421,  0.9918, -1.3834,  ..., -1.5574,  1.0691, -0.4293],\n",
       "         [-0.1621,  1.0194,  1.2018,  ...,  0.5483,  0.0334,  1.0089],\n",
       "         [-0.0446,  0.8425, -1.5088,  ...,  0.6599, -0.3981, -0.5852],\n",
       "         ...,\n",
       "         [ 0.2148,  0.9384, -0.6516,  ..., -1.8657, -0.6341, -0.0499],\n",
       "         [-0.2622,  0.1574,  0.3218,  ..., -1.7089, -1.6110,  0.0494],\n",
       "         [ 0.6504,  0.9134, -0.3202,  ...,  0.7525, -1.2522,  0.1003]]),\n",
       " tensor([[ 1.6421,  0.9918, -1.3834,  ..., -1.5574,  1.0691, -0.4293],\n",
       "         [-0.1621,  1.0194,  1.2018,  ...,  0.5483,  0.0334,  1.0089],\n",
       "         [-0.0446,  0.8425, -1.5088,  ...,  0.6599, -0.3981, -0.5852],\n",
       "         ...,\n",
       "         [ 0.2148,  0.9384, -0.6516,  ..., -1.8657, -0.6341, -0.0499],\n",
       "         [-0.2622,  0.1574,  0.3218,  ..., -1.7089, -1.6110,  0.0494],\n",
       "         [ 0.6504,  0.9134, -0.3202,  ...,  0.7525, -1.2522,  0.1003]])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr = next(iter(train_dataloader))\n",
    "pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02749740-18f5-4c3d-b7ac-5f12e3b20897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encode(pr).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c586c15-5fff-4f30-af01-589eb9911e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = []\n",
    "for idx, x_data in enumerate(pr):\n",
    "    encoder = getattr(model, f\"encoder_{idx}\")\n",
    "    z.append(encoder(x_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a41afc5-8f24-4730-9995-0d27e4d6598c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 50]), torch.Size([32, 50]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[0].shape, z[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "78e64015-6bea-41b9-b655-e7913aa18cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(z, dim = 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0271f708-e45b-48ff-b43c-012637be8363",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/alberto/anaconda3/envs/course_interpretability_dl/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:67: UserWarning: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "  warning_cache.warn(\n",
      "/home/alberto/anaconda3/envs/course_interpretability_dl/lib/python3.10/site-packages/pytorch_lightning/loops/utilities.py:70: PossibleUserWarning: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
      "  rank_zero_warn(\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type | Params\n",
      "-----------------------------------\n",
      "0 | encoder_0 | MLP  | 15.2 K\n",
      "1 | decoder_0 | MLP  | 17.9 K\n",
      "2 | encoder_1 | MLP  | 15.2 K\n",
      "3 | decoder_1 | MLP  | 17.9 K\n",
      "-----------------------------------\n",
      "66.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "66.2 K    Total params\n",
      "0.265     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a954e8fa60e4a0aa49a2c2fa5b37e40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alberto/anaconda3/envs/course_interpretability_dl/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:478: PossibleUserWarning: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "  rank_zero_warn(\n",
      "/home/alberto/anaconda3/envs/course_interpretability_dl/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (29x150 and 250x50)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/course_interpretability_dl/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:520\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    518\u001b[0m model \u001b[38;5;241m=\u001b[39m _maybe_unwrap_optimized(model)\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m_lightning_module \u001b[38;5;241m=\u001b[39m model\n\u001b[0;32m--> 520\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/course_interpretability_dl/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 44\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/anaconda3/envs/course_interpretability_dl/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:559\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_connector\u001b[38;5;241m.\u001b[39mattach_data(\n\u001b[1;32m    550\u001b[0m     model, train_dataloaders\u001b[38;5;241m=\u001b[39mtrain_dataloaders, val_dataloaders\u001b[38;5;241m=\u001b[39mval_dataloaders, datamodule\u001b[38;5;241m=\u001b[39mdatamodule\n\u001b[1;32m    551\u001b[0m )\n\u001b[1;32m    553\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    555\u001b[0m     ckpt_path,\n\u001b[1;32m    556\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    557\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    558\u001b[0m )\n\u001b[0;32m--> 559\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/course_interpretability_dl/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:935\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    932\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    933\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 935\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    939\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    940\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/course_interpretability_dl/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:976\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    974\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[1;32m    975\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n\u001b[0;32m--> 976\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_sanity_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    977\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[1;32m    978\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_loop\u001b[38;5;241m.\u001b[39mrun()\n",
      "File \u001b[0;32m~/anaconda3/envs/course_interpretability_dl/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1005\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1002\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1004\u001b[0m \u001b[38;5;66;03m# run eval step\u001b[39;00m\n\u001b[0;32m-> 1005\u001b[0m \u001b[43mval_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1007\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;66;03m# reset logger connector\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/course_interpretability_dl/lib/python3.10/site-packages/pytorch_lightning/loops/utilities.py:177\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m     context_manager \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mno_grad\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[0;32m--> 177\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/course_interpretability_dl/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py:115\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    113\u001b[0m     previous_dataloader_idx \u001b[38;5;241m=\u001b[39m dataloader_idx\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;66;03m# run step hooks\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/course_interpretability_dl/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py:375\u001b[0m, in \u001b[0;36m_EvaluationLoop._evaluation_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_started()\n\u001b[1;32m    374\u001b[0m hook_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_step\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mtesting \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 375\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstep_kwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_processed()\n\u001b[1;32m    379\u001b[0m hook_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_test_batch_end\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mtesting \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_validation_batch_end\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/course_interpretability_dl/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:288\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 288\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    291\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/anaconda3/envs/course_interpretability_dl/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py:378\u001b[0m, in \u001b[0;36mStrategy.validation_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision_plugin\u001b[38;5;241m.\u001b[39mval_step_context():\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, ValidationStep)\n\u001b[0;32m--> 378\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Work/course_interpretability_deep_learning/src/model/model.py:72\u001b[0m, in \u001b[0;36mMVAutoencoder.validation_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidation_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, batch_idx):\n\u001b[0;32m---> 72\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_reconstruction_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, loss)\n",
      "File \u001b[0;32m~/Work/course_interpretability_deep_learning/src/model/model.py:55\u001b[0m, in \u001b[0;36mMVAutoencoder._get_reconstruction_loss\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_reconstruction_loss\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m     54\u001b[0m     x \u001b[38;5;241m=\u001b[39m batch  \u001b[38;5;66;03m# We do not need the labels\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m     x_hat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m     loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmse_loss(torch\u001b[38;5;241m.\u001b[39mcat(x, dim\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m), torch\u001b[38;5;241m.\u001b[39mcat(x_hat, dim\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/Work/course_interpretability_deep_learning/src/model/model.py:31\u001b[0m, in \u001b[0;36mMVAutoencoder.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 31\u001b[0m     z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m     x_hat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecode(z)\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x_hat\n",
      "File \u001b[0;32m~/Work/course_interpretability_deep_learning/src/model/model.py:40\u001b[0m, in \u001b[0;36mMVAutoencoder.encode\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, x_data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(x):\n\u001b[1;32m     39\u001b[0m     encoder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 40\u001b[0m     z\u001b[38;5;241m.\u001b[39mappend(\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_data\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     41\u001b[0m z \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(z, dim\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m z\n",
      "File \u001b[0;32m~/anaconda3/envs/course_interpretability_dl/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/course_interpretability_dl/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/course_interpretability_dl/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/course_interpretability_dl/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/course_interpretability_dl/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/course_interpretability_dl/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (29x150 and 250x50)"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer()\n",
    "trainer.fit(model= model, train_dataloaders= train_dataloader, val_dataloaders= val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2f337b43-7cb5-4932-8ba1-94cc488aedce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36832e01-16ad-421b-ac47-89cf60b27af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# torch.manual_seed(1)  \n",
    "with pl.utilities.seed.isolate_rng():\n",
    "    a = [torch.rand(1) for _ in range(3)]\n",
    "a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
